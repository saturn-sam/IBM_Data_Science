{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6ad7a5-5444-41e7-83b7-c1fc2d52cd72",
   "metadata": {},
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6125dc7-9567-4966-950b-47a805851af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aaf3ba-1785-4c3a-9839-d1978ff31923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c187169-aa20-4ad3-98eb-b75340c8b85c",
   "metadata": {},
   "source": [
    "How to deal with missing values\n",
    "\n",
    "- Drop The missing value\n",
    "  1. drop the variable\n",
    "  2. drop the data entry\n",
    "- Replace the missing values\n",
    "  1. replace it with average\n",
    "  2. replace with freequence\n",
    "  3. replace by other function"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f11b3113-2e05-43b3-89ca-ae80a0f9f4cb",
   "metadata": {},
   "source": [
    "Drop missing values\n",
    "------------------\n",
    "dataframes.dropna()\n",
    "    axis = 0 drop the entire row\n",
    "    axis = 1 drop the entire column\n",
    "\n",
    "df.dropna(subset['price'], axis=0, inplace = True)\n",
    "equivalent to\n",
    "df = df.dropna(subset['price'], axis=0)\n",
    "\n",
    "\n",
    "mean = df['column_name'].mean()\n",
    "df['column_name'].replace(np.nan,mean)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3ca99a3-e02a-45d5-adad-28e57815afda",
   "metadata": {},
   "source": [
    "\n",
    "Data Formatting\n",
    "------------------\n",
    "df.dtype() identify data type\n",
    "\n",
    "df.astype() convert data type\n",
    "df[\"price\"] = df[\"price\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a76e87d-d820-4afa-9d7c-a524f282b4ae",
   "metadata": {},
   "source": [
    "Normalization\n",
    "1. Simple feature scaling\n",
    "    x_new = x_old/x_max\n",
    "2. min-max\n",
    "    x_new = (x_old-x_min)/(x_max-x_min)\n",
    "3. z-score\n",
    "    x_new = (x_old-mu)/sigma"
   ]
  },
  {
   "cell_type": "raw",
   "id": "573fa478-98b2-47a1-8ca3-1b0aa1bdb3dc",
   "metadata": {},
   "source": [
    "Binning\n",
    "-------------------\n",
    "bins = np.linspace(min(df[\"price\"]), max(df[\"price\"]), 4)\n",
    "group_names = [\"Low\", \"Medium\", \"High\"]\n",
    "price['price-binned'] = pd.cut(df[\"price\"], bins, labels=group_names, include_lowest=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55d00099-78ce-4c00-ae0e-4be58f499bdd",
   "metadata": {},
   "source": [
    "Data formatting is critical for making data from various sources consistent and comparable.\n",
    "\n",
    "Master the techniques in Python to convert units of measurement, like transforming \"city miles per gallon\" to \"city-liters per 100 kilometers\" for ease of comparison and analysis.\n",
    "\n",
    "Acquire skills to identify and correct data types in Python, ensuring the data is accurately represented for subsequent statistical analyses.\n",
    "\n",
    "Data normalization helps make variables comparable and helps eliminate inherent biases in statistical models.\n",
    "\n",
    "You can apply Feature Scaling, Min-Max, and Z-Score to normalize data and apply each technique in Python using pandas’ methods.\n",
    "\n",
    "Binning is a method of data pre-processing to improve model accuracy and data visualization.\n",
    "\n",
    "Run binning techniques in Python using numpy's \"linspace\" and pandas' \"cut\" methods, particularly for numerical variables like \"price.\"\n",
    "\n",
    "Utilize histograms to visualize the distribution of binned data and gain insights into feature distributions.\n",
    "\n",
    "Statistical models generally require numerical inputs, making it necessary to convert categorical variables like \"fuel type\" into numerical formats.\n",
    "\n",
    "You can implement the one-hot encoding technique in Python using pandas’ get_dummies method to transform categorical variables into a format suitable for machine learning models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a2f2c-70e3-4609-98c8-ce813f4c93f3",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade7d3fb-388e-4c84-ad7e-649955fd03d3",
   "metadata": {},
   "source": [
    "*Descriptive Statistics*\n",
    "\n",
    "Useful methods for descriptive statistics\n",
    "- df.describe()\n",
    "- summarize catagorical data using value_counts\n",
    "- Box Plot\n",
    "- Scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ae011-2fa3-4fdf-ad8d-7ab278dadb84",
   "metadata": {},
   "source": [
    "*Group By in Python*\n",
    "- groupby method\n",
    "- pivot method\n",
    "- heatmap plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c03ac-0619-4747-98ef-9164e73744b5",
   "metadata": {},
   "source": [
    "#### Pearson Correlation\n",
    "- sns.regplot(x='Engine_size', y='price', data=df)\n",
    "\n",
    "*Correlation coefficient*\n",
    "- Close to +1: Large Positive relationship\n",
    "- Close to -1: Large Negative relationship\n",
    "- Close to 0: No relationship\n",
    "\n",
    "*P-Value*\n",
    "- P-value < 0.001 Strong certainty in the result\n",
    "- P-value < 0.05 Moderate certainty in the result\n",
    "- P-value < 0.1 Weak certainty in the result\n",
    "- P-value > 0. 1 No certainty in the result\n",
    "\n",
    "*Strong Correlation*\n",
    "\n",
    "- Correlation coefficient close to 1 or -1\n",
    "- P value less than 0.001"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4260ae7-ada0-4992-81c1-66aede750606",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "Tools like the 'describe' function in pandas can quickly calculate key statistical measures like mean, standard deviation, and quartiles for all numerical variables in your data frame. \n",
    "\n",
    "Use the 'value_counts' function to summarize data into different categories for categorical data. \n",
    "\n",
    "Box plots offer a more visual representation of the data's distribution for numerical data, indicating features like the median, quartiles, and outliers.\n",
    "\n",
    "Scatter plots are excellent for exploring relationships between continuous variables, like engine size and price, in a car data set.\n",
    "\n",
    "Use Pandas' 'groupby' method to explore relationships between categorical variables.\n",
    "\n",
    "Use pivot tables and heat maps for better data visualizations.\n",
    "\n",
    "Correlation between variables is a statistical measure that indicates how the changes in one variable might be associated with changes in another variable.\n",
    "\n",
    "When exploring correlation, use scatter plots combined with a regression line to visualize relationships between variables.\n",
    "\n",
    "Visualization functions like regplot, from the seaborn library, are especially useful for exploring correlation.\n",
    "\n",
    "The Pearson correlation, a key method for assessing the correlation between continuous numerical variables, provides two critical values—the coefficient, which indicates the strength and direction of the correlation, and the P-value, which assesses the certainty of the correlation.\n",
    "\n",
    "A correlation coefficient close to 1 or -1 indicates a strong positive or negative correlation, respectively, while one close to zero suggests no correlation.\n",
    "\n",
    "For P-values, values less than .001 indicate strong certainty in the correlation, while larger values indicate less certainty. Both the coefficient and P-value are important for confirming a strong correlation.\n",
    "\n",
    "Heatmaps provide a comprehensive visual summary of the strength and direction of correlations among multiple variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d70941-486f-484a-9118-c11c876000bc",
   "metadata": {},
   "source": [
    "#### Model Evaluation using plot\n",
    "\n",
    "- sns.regplot()\n",
    "- sns.residplot()\n",
    "- sns.distplot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b221750d-7898-4c8f-9220-4d0b1c1c2910",
   "metadata": {},
   "source": [
    "#### Polynomial Regression\n",
    "- Quadratic -2nd order\n",
    "- cubic - 3rd order\n",
    "- Higher order\n",
    "\n",
    "```python\n",
    "f = np.polyfit(x,y,3)\n",
    "p = np.poly1d(f)\n",
    "```\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pr = PolynomialFeatures(degree=2, include_bias=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d3f16-b56a-45f8-84b0-8043c55f784f",
   "metadata": {},
   "source": [
    "#### Ins sample Evaluation\n",
    "\n",
    "- Mean Square Error (MSE)\n",
    "  ```python\n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  ```\n",
    "- R Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c265e-5716-406a-8376-82f276a0419e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1014c9-c814-4d95-b5e3-2df9b054fb13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
